{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32da93f3-5179-4757-acaf-6e405996e738",
   "metadata": {},
   "source": [
    "# CSCI 580 Final Project\n",
    "## Handwritten Digit Recognition using MLP\n",
    "**Team Members:** Aaron Partridge\n",
    "\n",
    "\n",
    "This project trains a simple Multilayer Perceptron (MLP) to classify handwritten digits using the MNIST dataset, and evaluates its performance on custom handwritten digits collected by our team.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74835560-b342-48a4-9c9d-ee6ec9d98cec",
   "metadata": {},
   "source": [
    "# 1. Import Required Libraries\n",
    "We import PyTorch, torchvision, and other necessary libraries for data loading, model building, and training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59763860-b35a-43bd-b933-6b8ecf7adaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d15c99-60b1-41e1-9b55-c95fe381fb4e",
   "metadata": {},
   "source": [
    "# 2. Define Image Transform\n",
    "We define the transformations to normalize image data from [0, 255] pixel values to [-1.0, 1.0].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94dfc9d8-1dfa-40fd-8165-1e00bd5d02c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transform first\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e009a-a0ec-405f-afe3-9015aae989d1",
   "metadata": {},
   "source": [
    "# 3. Load MNIST Dataset\n",
    "Download the MNIST dataset with transformations applied during loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60992a5c-300c-4c0c-9aa1-aecde6643841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST datasets downloaded!\n"
     ]
    }
   ],
   "source": [
    "# Download MNIST dataset with transform applied\n",
    "trainset = datasets.MNIST(root='./MNIST_data', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST(root='./MNIST_data', download=True, train=False, transform=transform)\n",
    "\n",
    "print(\"MNIST datasets downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e2007-e9f5-498e-88f8-5053a5d7ef43",
   "metadata": {},
   "source": [
    "# 4. Load Group Handwritten Digits\n",
    "Load the handwritten digits collected by our team members into memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e969795a-83a7-4074-985f-21b619b6e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330, 28, 28)\n",
      "(330,)\n"
     ]
    }
   ],
   "source": [
    "# Load our group handwritten digits\n",
    "def ProjectDataLoader(path='./digits'):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.png'):\n",
    "            label = int(filename.split('-')[0])\n",
    "            img = Image.open(os.path.join(path, filename)).convert('L')  # grayscale\n",
    "            img = np.array(img)\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n",
    "images, labels = ProjectDataLoader()\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7ab50-2693-4411-b4f9-27ca8be565f9",
   "metadata": {},
   "source": [
    "# 5. Display a Sample Handwritten Digit\n",
    "(Optional) Visualize one of the handwritten digit images to verify correct loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebce9e96-722c-4dad-8c36-c36223c2e40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGxCAYAAADLfglZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhyElEQVR4nO3de3BU5eHG8WdJwhohWRtjkg2EGCnUSpCqIJd64TJmiCMVKWPETgvYMlIuigGpSCuISqyOFEcKqLVcChSmDgJWBogCoQ7QCQxWoJQBTSQoIUPEbAiwAXJ+fzDszzUBeQ8b3mzy/cyckT17npw3x5M8OXt51+M4jiMAACxoZXsAAICWixICAFhDCQEArKGEAADWUEIAAGsoIQCANZQQAMAaSggAYA0lBACwhhJCi7Rw4UJ5PB7t2LEjIl/P4/Fo3LhxEfla3/6a06dPd50/c+aMnn/+ed14443yer26+eab9cYbb0RugEAExNoeAIDGMWbMGP3tb3/TCy+8oB49emj9+vV68sknVV1drWeffdb28ABJlBDQLO3du1fvvPOOXnrpJT399NOSpL59+6qyslIvvviiRo8eraSkJMujBHg4Drio06dPa+LEifrJT34in8+npKQk9e7dW6tXr75o5s0331Tnzp3l9Xp1yy23aPny5fW2KS8v1+OPP6727durdevWysrK0vPPP6+zZ89GbOyrVq2S4zgaOXJk2PqRI0fq1KlTWrduXcT2BVwJroSAiwgGg/r66681adIktWvXTrW1tfrwww81ZMgQLViwQL/61a/Ctl+zZo02bdqkGTNmqE2bNpo7d66GDRum2NhYDR06VNL5ArrzzjvVqlUrPffcc+rYsaO2bdumF198UaWlpVqwYMElx3TjjTdKkkpLSy+53Z49e3TDDTcoLS0tbP2tt94auh9oCigh4CJ8Pl9YKZw7d04DBgzQ8ePHNXv27HoldOzYMRUXFys1NVWSdP/99ys7O1tTpkwJldD06dN1/Phx7d27Vx06dJAkDRgwQPHx8Zo0aZKefvpp3XLLLRcdU2zs5f3IVlZWNvhwW5s2bdS6dWtVVlZe1tcBGhsPxwGX8I9//EM//elP1bZtW8XGxiouLk7vvPOO9u3bV2/bAQMGhApIkmJiYpSXl6eDBw/q8OHDkqR//vOf6tevn9LT03X27NnQkpubK0kqKiq65HgOHjyogwcPXtbYPR6Pq/uAq4kSAi5i5cqVevjhh9WuXTstWbJE27ZtU3FxsR577DGdPn263vbffejr2+suXHkcPXpU77//vuLi4sKWLl26SDp/NRUJ119/fYNXOzU1NaqtreVFCWgyeDgOuIglS5YoKytLK1asCLtyCAaDDW5fXl5+0XXXX3+9JCk5OVm33nqrXnrppQa/Rnp6+pUOW5LUtWtXLV++XOXl5WHluHv3bklSdnZ2RPYDXCmuhICL8Hg8at26dVgBlZeXX/TVcR999JGOHj0aun3u3DmtWLFCHTt2VPv27SVJDzzwgPbs2aOOHTuqe/fu9ZZIldCDDz4oj8ejRYsWha1fuHCh4uPjNXDgwIjsB7hSXAmhRdu4cWODrzS7//779cADD2jlypUaM2aMhg4dqrKyMr3wwgvy+/06cOBAvUxycrL69++vP/zhD6FXx/3vf/8Le5n2jBkzVFhYqD59+uiJJ57Qj370I50+fVqlpaVau3at5s+fHyqshvzwhz+UpO99XqhLly769a9/rWnTpikmJkY9evTQhg0b9NZbb+nFF1/k4Tg0GZQQWrTf/e53Da4vKSnRyJEjVVFRofnz5+uvf/2rbrrpJj3zzDM6fPiwnn/++XqZn/3sZ+rSpYt+//vf69ChQ+rYsaOWLl2qvLy80DZ+v187duzQCy+8oFdffVWHDx9WQkKCsrKyNHDgQP3gBz+45HhN3ks0d+5ctWvXTm+88YbKy8t144036vXXX9f48eMv+2sAjc3jOI5jexAAgJaJ54QAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALCmyb1PqK6uTl999ZUSEhKYZBEAopDjOKqurlZ6erpatbr0tU6TK6GvvvpKGRkZtocBALhCZWVll5wBRGqCJZSQkCBJ9ebsAgBEB8dxVFtbG/p9fimNVkJz587Vq6++qiNHjqhLly6aPXu27r777u/NXSgej8dDCQFAFLuc3+GN8sKEFStWaMKECZo6dap27dqlu+++W7m5uTp06FBj7A4AEKUaZe64nj176vbbb9e8efNC63784x9r8ODBKigouGQ2EAjI5/PJ6/VyJQQAUchxHAWDQVVVVSkxMfGS20b8Sqi2tlY7d+5UTk5O2PqcnBxt3bq13vbBYFCBQCBsAQC0DBEvoWPHjuncuXNKTU0NW5+amtrgJ08WFBTI5/OFFl4ZBwAtR6O9WfW7D6U5jtPgw2tTpkxRVVVVaCkrK2usIQEAmpiIvzouOTlZMTEx9a56Kioq6l0dSZLX65XX6430MAAAUSDiV0KtW7fWHXfcocLCwrD1Fz7SGACACxrlfUL5+fn65S9/qe7du6t379566623dOjQIY0ePboxdgcAiFKNUkJ5eXmqrKzUjBkzdOTIEWVnZ2vt2rXKzMxsjN0BAKJUo7xP6ErwPiEAiG5W3ycEAMDlooQAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALCGEgIAWEMJAQCsoYQAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALCGEgIAWEMJAQCsoYQAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALCGEgIAWEMJAQCsoYQAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALCGEgIAWEMJAQCsoYQAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALAm1vYAgGhXV1d3VfbTqhV/M6L54awGAFhDCQEArKGEAADWUEIAAGsoIQCANZQQAMAaSggAYA0lBACwhhICAFhDCQEArKGEAADWUEIAAGuYwBSuJ+B0HOeq7MtNxs3YJMnj8Rhn2rZt62pfpk6ePGmccfv/1s1kqTExMVdlP2heOAMAANZQQgAAayJeQtOnT5fH4wlb0tLSIr0bAEAz0CjPCXXp0kUffvhh6Labx4oBAM1fo5RQbGwsVz8AgO/VKM8JHThwQOnp6crKytIjjzyizz///KLbBoNBBQKBsAUA0DJEvIR69uypxYsXa/369Xr77bdVXl6uPn36qLKyssHtCwoK5PP5QktGRkakhwQAaKI8jts3VFymmpoadezYUZMnT1Z+fn69+4PBoILBYOh2IBBQRkaGvF6vq/dswBzvE/p/vE/oPN4nhCvhOI6CwaCqqqqUmJh4yW0b/c2qbdq0UdeuXXXgwIEG7/d6vfJ6vY09DABAE9Tof4YEg0Ht27dPfr+/sXcFAIgyES+hSZMmqaioSCUlJfr3v/+toUOHKhAIaPjw4ZHeFQAgykX84bjDhw9r2LBhOnbsmG644Qb16tVL27dvV2ZmZqR3BQCIco3+wgRTgUBAPp+PFybI3ZPK586dM85cc801xhlJrl7J2K5du6uS6dSpk3FGkjp06GCcSUlJcbUvU6WlpcaZbdu2udrXf/7zH+PMF198YZypqakxzvDm96bP5IUJvDQFAGANJQQAsIYSAgBYQwkBAKyhhAAA1lBCAABrKCEAgDWUEADAGkoIAGANJQQAsIYSAgBYQwkBAKxp9A+1w3luJl10MzHmT3/6U+PM0KFDjTOS1K1bN+NMbKz5KXfdddcZZ9xM5CpJ+/fvN87s2bPHOHPmzBnjzE033WScGTBggHFGkuLj440z+/btM8786U9/Ms5s2rTJOIOmiyshAIA1lBAAwBpKCABgDSUEALCGEgIAWEMJAQCsoYQAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALCGEgIAWONxHMexPYhvCwQC8vl88nq98ng8tofToGAwaJzp27evcebFF180znTq1Mk4s3XrVuOMJL377rvGmYMHDxpn3JyiR48eNc5IUmVlpXHGzYzYdXV1xhmv12uc8fv9xhnJ3QzpEydONM64mRk8Ly/POPPxxx8bZyR3s9/j/M9sMBhUVVWVEhMTL7ktV0IAAGsoIQCANZQQAMAaSggAYA0lBACwhhICAFhDCQEArKGEAADWUEIAAGsoIQCANZQQAMAaSggAYA0TmLrgZvLJ9PR040y/fv2MM7fddptx5ssvvzTOSNKbb75pnKmurna1L1OtWrn7+6qpnnNuuf3xdjMpa+fOnY0z7733nnHGzUSuQ4cONc5I0t69e40zTHrKBKYAgChBCQEArKGEAADWUEIAAGsoIQCANZQQAMAaSggAYA0lBACwhhICAFhDCQEArKGEAADWUEIAAGtibQ+gpTh+/Lhx5s477zTOjB492jizePFi44wkxcaanz5uJnd0Oxkp3HPz/+mzzz4zzowbN844s3btWuPME088YZyRpCeffNI4EwwGjTMt+Rxvud85AMA6SggAYI1xCW3ZskWDBg1Senq6PB6PVq1aFXa/4ziaPn260tPTFR8fr759+7r6TA4AQPNnXEI1NTXq1q2b5syZ0+D9r7zyimbNmqU5c+aouLhYaWlpuu+++67ah5kBAKKH8TPLubm5ys3NbfA+x3E0e/ZsTZ06VUOGDJEkLVq0SKmpqVq2bJkef/zxKxstAKBZiehzQiUlJSovL1dOTk5ondfr1b333qutW7c2mAkGgwoEAmELAKBliGgJlZeXS5JSU1PD1qempobu+66CggL5fL7QkpGREckhAQCasEZ5dZzH4wm77ThOvXUXTJkyRVVVVaGlrKysMYYEAGiCIvpm1bS0NEnnr4j8fn9ofUVFRb2rowu8Xq+8Xm8khwEAiBIRvRLKyspSWlqaCgsLQ+tqa2tVVFSkPn36RHJXAIBmwPhK6MSJEzp48GDodklJiT755BMlJSWpQ4cOmjBhgmbOnKlOnTqpU6dOmjlzpq699lo9+uijER04ACD6GZfQjh071K9fv9Dt/Px8SdLw4cO1cOFCTZ48WadOndKYMWN0/Phx9ezZUxs2bFBCQkLkRg0AaBY8juM4tgfxbYFAQD6fT16v96IvZrCtrq7OODN27FjjzB//+EfjzNSpU40zCxcuNM5IUlVVlXGmJU/UiPrOnDljnHnuueeMM5MmTTLOSNLDDz9snNmwYYNxxs2EsU2Z4zgKBoOqqqpSYmLiJbflNwIAwBpKCABgDSUEALCGEgIAWEMJAQCsoYQAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALCGEgIAWEMJAQCsadGzaLuZwVeSOnbsaJxZt26dcWb79u3Gmd/85jfGGbfHobnN/Iurz8255+bn79sftGli7dq1xpmnnnrK1b6aE2bRBgBEBUoIAGANJQQAsIYSAgBYQwkBAKyhhAAA1lBCAABrKCEAgDWUEADAGkoIAGANJQQAsIYSAgBYE2t7ADbV1dW5yrVr1844k5ycbJzZsmWLcebUqVPGGa/Xa5wBIsHNJLgVFRXGmT179hhnJKlDhw7GmbZt2xpnAoGAcaZVq+ZxDdE8vgsAQFSihAAA1lBCAABrKCEAgDWUEADAGkoIAGANJQQAsIYSAgBYQwkBAKyhhAAA1lBCAABrKCEAgDUtegJTt6677jrjzJkzZ4wzlZWVxpnmMqkhcDGO4xhn3Pz8SVJiYqJxJi4uztW+Wip+YwEArKGEAADWUEIAAGsoIQCANZQQAMAaSggAYA0lBACwhhICAFhDCQEArKGEAADWUEIAAGsoIQCANUxg6kJdXd1V2Y+biRoBRA4TAjc+jjAAwBpKCABgjXEJbdmyRYMGDVJ6ero8Ho9WrVoVdv+IESPk8XjCll69ekVqvACAZsS4hGpqatStWzfNmTPnotsMHDhQR44cCS1r1669okECAJon4xcm5ObmKjc395LbeL1epaWluR4UAKBlaJTnhDZv3qyUlBR17txZo0aNUkVFxUW3DQaDCgQCYQsAoGWIeAnl5uZq6dKl2rhxo1577TUVFxerf//+CgaDDW5fUFAgn88XWjIyMiI9JABAExXx9wnl5eWF/p2dna3u3bsrMzNTH3zwgYYMGVJv+ylTpig/Pz90OxAIUEQA0EI0+ptV/X6/MjMzdeDAgQbv93q98nq9jT0MAEAT1OjvE6qsrFRZWZn8fn9j7woAEGWMr4ROnDihgwcPhm6XlJTok08+UVJSkpKSkjR9+nT9/Oc/l9/vV2lpqZ599lklJyfroYceiujAAQDRz7iEduzYoX79+oVuX3g+Z/jw4Zo3b552796txYsX65tvvpHf71e/fv20YsUKJSQkRG7UAIBmwbiE+vbte8mJNdevX39FA4oGR48eNc7ExcUZZzp27GicAZo7j8djnImJiXG1r7NnzxpnrtYEx80Fc8cBAKyhhAAA1lBCAABrKCEAgDWUEADAGkoIAGANJQQAsIYSAgBYQwkBAKyhhAAA1lBCAABrKCEAgDWUEADAmkb/ZNWmLDbW3bf/xRdfGGf27NljnOnfv79x5u233zbOnDhxwjgjSa1a8TcMrsylZuS/GDc/t23atDHOSFJVVZVxJhgMutpXS8VvEQCANZQQAMAaSggAYA0lBACwhhICAFhDCQEArKGEAADWUEIAAGsoIQCANZQQAMAaSggAYA0lBACwpkVPYBoTE+MqV1FRYZxZvXq1cWbq1KnGmdtuu804s2XLFuMMEAl1dXXGmeTkZONMhw4djDOS9P777xtnampqjDNufxc1B1wJAQCsoYQAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALCGEgIAWEMJAQCsoYQAANZQQgAAayghAIA1LXoCU7datTLvbjcTmI4ZM8Y489hjjxlndu7caZyRmKgRV87NBKa9e/c2zqSmphpnJGnr1q2ucrh8XAkBAKyhhAAA1lBCAABrKCEAgDWUEADAGkoIAGANJQQAsIYSAgBYQwkBAKyhhAAA1lBCAABrKCEAgDVMYOqCm0k4P/vsM+PM/PnzjTPPPfeccWbNmjXGGUl69913jTMej8c442bCWFx9586dM85ce+21xpkhQ4YYZ0pKSowzklRcXOwqh8vHTzcAwBpKCABgjVEJFRQUqEePHkpISFBKSooGDx6s/fv3h23jOI6mT5+u9PR0xcfHq2/fvtq7d29EBw0AaB6MSqioqEhjx47V9u3bVVhYqLNnzyonJyfsw81eeeUVzZo1S3PmzFFxcbHS0tJ03333qbq6OuKDBwBEN6MXJqxbty7s9oIFC5SSkqKdO3fqnnvukeM4mj17tqZOnRp68nDRokVKTU3VsmXL9Pjjj0du5ACAqHdFzwlVVVVJkpKSkiSdfwVKeXm5cnJyQtt4vV7de++9F/2Y3GAwqEAgELYAAFoG1yXkOI7y8/N11113KTs7W5JUXl4uqf7nuaempobu+66CggL5fL7QkpGR4XZIAIAo47qExo0bp08//VR///vf69333feCOI5z0feHTJkyRVVVVaGlrKzM7ZAAAFHG1ZtVx48frzVr1mjLli1q3759aH1aWpqk81dEfr8/tL6ioqLe1dEFXq9XXq/XzTAAAFHO6ErIcRyNGzdOK1eu1MaNG5WVlRV2f1ZWltLS0lRYWBhaV1tbq6KiIvXp0ycyIwYANBtGV0Jjx47VsmXLtHr1aiUkJISe5/H5fIqPj5fH49GECRM0c+ZMderUSZ06ddLMmTN17bXX6tFHH22UbwAAEL2MSmjevHmSpL59+4atX7BggUaMGCFJmjx5sk6dOqUxY8bo+PHj6tmzpzZs2KCEhISIDBgA0Hx4HMdxbA/i2wKBgHw+n7xer6vJLpuquro644zP5zPOLFmyxDjTvXt344wkDRs2zDjz0UcfGWfi4uKMM7gybs5XN0aNGmWcmTVrlnFm8uTJxhnp///wNsGEu+efugkGg6qqqlJiYuIlt+VoAQCsoYQAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALCGEgIAWEMJAQCsoYQAANZQQgAAayghAIA1lBAAwBpm0W7Czpw5Y5zJzs42zqxevdo4I7mbafnhhx82zuzatcs441ZMTMxV25cpNz+qZ8+edbWvb38y8uWaOnWqceYXv/iFcWbp0qXGmRkzZhhnJOnrr782zjTlc+hqYRZtAEBUoIQAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALCGEgIAWEMJAQCsoYQAANZQQgAAayghAIA1TGDazJw7d844c/vtt7va1+LFi40zbdu2Nc785S9/Mc68//77xhlJKi0tNc64mWjWzbkdHx9vnElKSjLOSO4m/Lz//vuNM0899ZRxZvny5caZkydPGmckqVUr/k53gwlMAQBRgRICAFhDCQEArKGEAADWUEIAAGsoIQCANZQQAMAaSggAYA0lBACwhhICAFhDCQEArKGEAADWMIEpXE3AKUlZWVnGmZEjRxpnBg0aZJyJi4szzkjSl19+aZwJBoPGGa/Xa5xxM4HpddddZ5yRpNOnTxtnXn/9deOMm8lI3WAi0quLCUwBAFGBEgIAWEMJAQCsoYQAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALCGEgIAWEMJAQCsoYQAANYwgSlcO3fu3FXZT2pqqnGmW7durvZ10003GWdSUlKMMzExMcaZI0eOGGdKS0uNM5K0e/du44ybyV/dHAc0fUxgCgCICpQQAMAaoxIqKChQjx49lJCQoJSUFA0ePFj79+8P22bEiBHyeDxhS69evSI6aABA82BUQkVFRRo7dqy2b9+uwsJCnT17Vjk5OaqpqQnbbuDAgTpy5EhoWbt2bUQHDQBoHmJNNl63bl3Y7QULFiglJUU7d+7UPffcE1rv9XqVlpYWmRECAJqtK3pOqKqqSpKUlJQUtn7z5s1KSUlR586dNWrUKFVUVFz0awSDQQUCgbAFANAyuC4hx3GUn5+vu+66S9nZ2aH1ubm5Wrp0qTZu3KjXXntNxcXF6t+/v4LBYINfp6CgQD6fL7RkZGS4HRIAIMoYPRz3bePGjdOnn36qjz/+OGx9Xl5e6N/Z2dnq3r27MjMz9cEHH2jIkCH1vs6UKVOUn58fuh0IBCgiAGghXJXQ+PHjtWbNGm3ZskXt27e/5LZ+v1+ZmZk6cOBAg/d7vV55vV43wwAARDmjEnIcR+PHj9d7772nzZs3Kysr63szlZWVKisrk9/vdz1IAEDzZPSc0NixY7VkyRItW7ZMCQkJKi8vV3l5uU6dOiVJOnHihCZNmqRt27aptLRUmzdv1qBBg5ScnKyHHnqoUb4BAED0MroSmjdvniSpb9++YesXLFigESNGKCYmRrt379bixYv1zTffyO/3q1+/flqxYoUSEhIiNmgAQPNg/HDcpcTHx2v9+vVXNCAAQMvBLNpo8urq6owzZ86caYSRNCw21vWLTI2cPXv2quxHkuLi4owzrVoxFSXOYxZtAEBUoIQAANZQQgAAayghAIA1lBAAwBpKCABgDSUEALCGEgIAWEMJAQCsoYQAANZQQgAAayghAIA1V2fmReAKuJkYszl+Wm9MTIztIQARx5UQAMAaSggAYA0lBACwhhICAFhDCQEArKGEAADWUEIAAGsoIQCANZQQAMAaSggAYA0lBACwpsnNHec4Tth/AQDRxeT3eJMroerqaklSbW2t5ZEAAK5EdXW1fD7fJbfxOE3skqOurk5fffWVEhIS5PF4wu4LBALKyMhQWVmZEhMTLY3QPo7DeRyH8zgO53EczmsKx8FxHFVXVys9Pf17Z8FvcldCrVq1Uvv27S+5TWJiYos+yS7gOJzHcTiP43Aex+E828fh+66ALuCFCQAAayghAIA1UVVCXq9X06ZNa5afmmmC43Aex+E8jsN5HIfzou04NLkXJgAAWo6ouhICADQvlBAAwBpKCABgDSUEALCGEgIAWBNVJTR37lxlZWXpmmuu0R133KF//etftod0VU2fPl0ejydsSUtLsz2sRrdlyxYNGjRI6enp8ng8WrVqVdj9juNo+vTpSk9PV3x8vPr27au9e/faGWwj+r7jMGLEiHrnR69evewMtpEUFBSoR48eSkhIUEpKigYPHqz9+/eHbdMSzofLOQ7Rcj5ETQmtWLFCEyZM0NSpU7Vr1y7dfffdys3N1aFDh2wP7arq0qWLjhw5Elp2795te0iNrqamRt26ddOcOXMavP+VV17RrFmzNGfOHBUXFystLU333XdfaDLc5uL7joMkDRw4MOz8WLt27VUcYeMrKirS2LFjtX37dhUWFurs2bPKyclRTU1NaJuWcD5cznGQouR8cKLEnXfe6YwePTps3c033+w888wzlkZ09U2bNs3p1q2b7WFYJcl57733Qrfr6uqctLQ05+WXXw6tO336tOPz+Zz58+dbGOHV8d3j4DiOM3z4cOfBBx+0Mh5bKioqHElOUVGR4zgt93z47nFwnOg5H6LiSqi2tlY7d+5UTk5O2PqcnBxt3brV0qjsOHDggNLT05WVlaVHHnlEn3/+ue0hWVVSUqLy8vKwc8Pr9eree+9tceeGJG3evFkpKSnq3LmzRo0apYqKCttDalRVVVWSpKSkJEkt93z47nG4IBrOh6gooWPHjuncuXNKTU0NW5+amqry8nJLo7r6evbsqcWLF2v9+vV6++23VV5erj59+qiystL20Ky58P+/pZ8bkpSbm6ulS5dq48aNeu2111RcXKz+/fsrGAzaHlqjcBxH+fn5uuuuu5SdnS2pZZ4PDR0HKXrOhyb3UQ6X8t3PF3Icp9665iw3Nzf0765du6p3797q2LGjFi1apPz8fIsjs6+lnxuSlJeXF/p3dna2unfvrszMTH3wwQcaMmSIxZE1jnHjxunTTz/Vxx9/XO++lnQ+XOw4RMv5EBVXQsnJyYqJian3l0xFRUW9v3hakjZt2qhr1646cOCA7aFYc+HVgZwb9fn9fmVmZjbL82P8+PFas2aNNm3aFPb5Yy3tfLjYcWhIUz0foqKEWrdurTvuuEOFhYVh6wsLC9WnTx9Lo7IvGAxq37598vv9todiTVZWltLS0sLOjdraWhUVFbXoc0OSKisrVVZW1qzOD8dxNG7cOK1cuVIbN25UVlZW2P0t5Xz4vuPQkCZ7Plh8UYSR5cuXO3Fxcc4777zj/Pe//3UmTJjgtGnTxiktLbU9tKtm4sSJzubNm53PP//c2b59u/PAAw84CQkJzf4YVFdXO7t27XJ27drlSHJmzZrl7Nq1y/niiy8cx3Gcl19+2fH5fM7KlSud3bt3O8OGDXP8fr8TCAQsjzyyLnUcqqurnYkTJzpbt251SkpKnE2bNjm9e/d22rVr16yOw29/+1vH5/M5mzdvdo4cORJaTp48GdqmJZwP33ccoul8iJoSchzH+fOf/+xkZmY6rVu3dm6//fawlyO2BHl5eY7f73fi4uKc9PR0Z8iQIc7evXttD6vRbdq0yZFUbxk+fLjjOOdfljtt2jQnLS3N8Xq9zj333OPs3r3b7qAbwaWOw8mTJ52cnBznhhtucOLi4pwOHTo4w4cPdw4dOmR72BHV0PcvyVmwYEFom5ZwPnzfcYim84HPEwIAWBMVzwkBAJonSggAYA0lBACwhhICAFhDCQEArKGEAADWUEIAAGsoIQCANZQQAMAaSggAYA0lBACw5v8ANkzVIDlZqa4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test: show one sample\n",
    "sample_img = images[0]\n",
    "sample_img_tensor = transform(sample_img)\n",
    "\n",
    "print(sample_img_tensor.shape)  # Should be [1, 28, 28]\n",
    "\n",
    "plt.imshow(sample_img_tensor.squeeze(0), cmap='gray')\n",
    "plt.title(f\"Label: {labels[0]}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad0d092-3db0-4fec-84d3-3ecd80b09326",
   "metadata": {},
   "source": [
    "# 6. Define the MLP Model\n",
    "We define a simple 3-layer Multilayer Perceptron for classifying digit images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f59a2f-c3a0-4192-8bfe-ec926ac4cd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Flatten the image\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ec041-9e7a-4f84-9653-273c7e74f30a",
   "metadata": {},
   "source": [
    "# 7. Define Loss Function and Optimizer\n",
    "Set up Cross Entropy Loss and Adam optimizer for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d02211a1-73d2-49b7-814e-250613985424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61526399-88ee-48ba-969a-844dcef96526",
   "metadata": {},
   "source": [
    "# 8. Train the Model\n",
    "Train the MLP using the MNIST training set for a fixed number of epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e505b6-bf22-4fea-9bce-c64da68672f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.33759272978631166\n",
      "Epoch 2, Loss: 0.14877128409845297\n",
      "Epoch 3, Loss: 0.10861040835481273\n",
      "Epoch 4, Loss: 0.0894225395085024\n",
      "Epoch 5, Loss: 0.07464617934784909\n",
      "Epoch 6, Loss: 0.06438211400631759\n",
      "Epoch 7, Loss: 0.0564301806198719\n",
      "Epoch 8, Loss: 0.0516386339443424\n",
      "Epoch 9, Loss: 0.04564529160414435\n",
      "Epoch 10, Loss: 0.04105471446166939\n",
      "Epoch 11, Loss: 0.03743123086462262\n",
      "Epoch 12, Loss: 0.03638833493024033\n",
      "Epoch 13, Loss: 0.033971292576272294\n",
      "Epoch 14, Loss: 0.028871398275794546\n",
      "Epoch 15, Loss: 0.027702392989718445\n",
      "Epoch 16, Loss: 0.029365235246730466\n",
      "Epoch 17, Loss: 0.02668613352433391\n",
      "Epoch 18, Loss: 0.02504911250259898\n",
      "Epoch 19, Loss: 0.02304051708091068\n",
      "Epoch 20, Loss: 0.021094783838430994\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Corrected Training Loop\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images_batch, labels_batch in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images_batch)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f266b59-4597-4fdd-a91a-ee156ef81473",
   "metadata": {},
   "source": [
    "# 9. Test Accuracy on MNIST Dataset\n",
    "Evaluate the trained model on the MNIST test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d0fcb72-f3d9-405a-89be-7760ccf6a023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on MNIST: 97.88%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on MNIST Test set\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images_batch, labels_batch in testloader:\n",
    "        outputs = model(images_batch)  # <-- No transform needed!\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels_batch.size(0)\n",
    "        correct += (predicted == labels_batch).sum().item()\n",
    "\n",
    "mnist_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy on MNIST: {mnist_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d581995-d2da-48ff-858b-68fc270f2ad6",
   "metadata": {},
   "source": [
    "# 10. Test Accuracy on Group Handwritten Digits\n",
    "Evaluate the trained model on the handwritten digits collected by our team.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7374e03-4bd6-42cd-9afd-8744a0022fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on Team Digits: 33.94%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on your group's digits\n",
    "correct = 0\n",
    "total = images.shape[0]\n",
    "\n",
    "for idx in range(total):\n",
    "    img = images[idx]\n",
    "    label = labels[idx]\n",
    "\n",
    "    img_tensor = transform(img)\n",
    "    img_tensor = img_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    output = model(img_tensor)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "    if predicted.item() == label:\n",
    "        correct += 1\n",
    "\n",
    "group_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy on Team Digits: {group_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adf2590d-e497-412d-9187-fd5ef4212100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# 11. Summary of Results\n",
       "\n",
       "**MNIST Test Accuracy:** 97.88%  \n",
       "**Group Digits Test Accuracy:** 33.94%\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "# 11. Summary of Results\n",
    "\n",
    "**MNIST Test Accuracy:** {mnist_accuracy:.2f}%  \n",
    "**Group Digits Test Accuracy:** {group_accuracy:.2f}%\n",
    "\n",
    "\"\"\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb23a1-f311-4a6d-a58e-d30430766157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
